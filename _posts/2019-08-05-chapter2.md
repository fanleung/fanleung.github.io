---
title: chapter2
categories:
- Learn-OpenCV-3-with-Python
tags:
- Python
- OpenCV
- 图像处理
---


### 第2章 处理文件、摄像头和图形用户界面

#### 2.1.1 读/写图像文件
OpenCV 的`imread()`函数 和 `imwrite()`函数能够支持各种静态图像文件格式，都支持BMP,通常还支持PNG、JPEG 和 TIFF 格式


```python
# 每个像素都有一个值，但不同格式表示像素的方式有所不同，例如通过二维 numpy 数组简单创建一个黑色的正方形
# 每个像素值的范围是 0-255
import numpy
img = numpy.zeros((3,3), dtype = numpy.uint8)
img
```




    array([[0, 0, 0],
           [0, 0, 0],
           [0, 0, 0]], dtype=uint8)




```python
# 使用 cv2.cvtColor 函数将图像转换成 RGB 格式
# 从结果可以看出，每个像素从之前一个值表示，变成由三元数组表示了，每个整型表示一个B, G, R通道
# 其他色彩空间（如HSV）也以同样的方式来表示像素， 只是取值范围和通道数目不同，HSV是 0-180
import cv2
img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
img
```




    array([[[0, 0, 0],
            [0, 0, 0],
            [0, 0, 0]],
    
           [[0, 0, 0],
            [0, 0, 0],
            [0, 0, 0]],
    
           [[0, 0, 0],
            [0, 0, 0],
            [0, 0, 0]]], dtype=uint8)




```python
# 执行第一步得到的结果是（3，3）
# 如果将图像转化为 BGR 格式，shape 会返回 （3,3,3），这表明每个像素存在三个通道
img = numpy.zeros((3,3), dtype = numpy.uint8)
img.shape
img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
img.shape
```




    (3, 3, 3)




```python
## 读取一种格式的图像文件 ，然后保存为另一种格式
import cv2
image = cv2.imread('../fanleungTest/test.png')
cv2.imwrite('../fanleungTest/test.jpg', image)
```




    True



> 在默认情况下，即时图像文件为灰度格式，`imread()` 函数也会返回 BGR 格式的图像，BGR 与 RGB 所表示的而是才空间相同，但字节顺序相反

以下为 imread() 函数的可选参数
- IMREAD_ANYCOLOR = 4
- IMREAD_ANYDEPTH = 2
- IMREAD_COLOR = 1
- IMREAD_GRAYSCALE = 0
- IMREAD_LOAD_GDAL = 8
- IMREAD_UNCHANGED = -1



```python
grayImage = cv2.imread('../fanleungTest/test.png', cv2.IMREAD_GRAYSCALE)
cv2.imwrite('../fanleungTest/testGray.png', grayImage)
```




    True



无论采用何种模式，imread()函数会删除所有alpha 通道的信息（透明度）, imwrite()函数要求函数为BGR 格式或灰度格式，并且每个通道要有一定的位（bit），输出格式要支持这些通道，如 bmp 格式要求每个通道有 8 位， 而 PNG 允许每个通道有 8 位或 16 位

####  2.1.2 图像和原始字节之间的转换
- 一个 OpenCV 图像是 array 类型的二维或三维数组，8位灰度图像是一个含有字节值的二维数组，24 位的 BGR 图像是一个三维数组，可使用表达式访问这些值。
- 例如image[0,0] 和 image[0, 0, 0],第一个值代表像素的 y 坐标或行，0 表示顶部， 第二个值是像素的 x 坐标或者列，0 表示最左边， 第三个值表示颜色通道
- 对于一个左上角有白色像素的 8 位灰度图像而言，image[0, 0] = 255, 对于一个左上角有蓝色像素的 24 位 BGR 图像而言， image[0, 0] = [255, 0, 0]

##### 将随机字节 bytearray 转化为 灰度图像 和 BGR 图像


```python
import cv2
import numpy
import os
# make an array of 120,000 random bytes
#randomByteArray = bytearray(os.urandom(120000))
randomByteArray = numpy.random.randint(0, 256, 120000)
#randomByteArray
```


```python
flatNumpyArray = numpy.array(randomByteArray)
#flatNumpyArray
```


```python
# Convert the array to make a 400x300 grayscale image
grayImage = flatNumpyArray.reshape(400, 300)
cv2.imwrite('../fanleungTest/RandomGray.png', grayImage)
```




    True




```python
# Convert the array to make a 400x300 color image
bgrImage = flatNumpyArray.reshape(100, 400, 3)
cv2.imwrite('../fanleungTest/RandomColor.png', bgrImage)
```




    True




```python
# 制作数据也可以一句代码实现
grayImage = numpy.random.randint(0, 256, 120000).reshape(400, 300)
```

#### 2.1.3 使用 numpy.array 访问图像数据


```python
# 由于在jupyter notebook 中调用 cv2.imshow() 会奔溃，这里重构一下函数
# 也可以使用 from matplotlib import pyplot as plt 来显示图片
# plt.imshow(img)
# plt.show()
def cv2_imshow(img):
    cv2.imshow('temp', img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()

```

##### 将 BGR 图像在 (0, 0)处的像素转化为白色


```python
import cv2
import numpy as np
img = cv2.imread('../fanleungTest/MyPic.png')
img[0,0] = [255, 255, 255]
cv2_imshow(img)
```

##### 将坐标 (150, 120) 的当前蓝色值（127）改成 255
- numpy.array 提供的 item() 方法非常方便，该函数有三个参数：x,y,BGR的通道值：0是B，1是G, 2是R, 返回索引的值
- itemset()函数可设置指定像素在指定通道的值，itemset()函数有两个参数：三元组（x,y,通道值）和要设置的值


```python
import cv2
import numpy as np
img = cv2.imread('../fanleungTest/MyPic.png')
print(img.item(150, 120, 0))

```

    168
    


```python
img.itemset((150,120,0), 255)
print(img.item(150, 120, 0))
cv2_imshow(img)
```

    255
    

> 使用 numpy.array 的原因有两个numpy.array 经过优化，可读性强，这里不使用第一个示例的方式访问原始索引

这种特殊的代码本身并不能完成多少功能，但它提供了一种解决方案。然而，建议使用内置的滤波器和方法来处理整个图像，上述方法只适合处理特定的小区域。

> 提示：通过循环来处理 python 的数据效率非常低，应尽量避免这种方式。使用数组索引可以高效地操作像素。像素操作是一个高代价的低效操作，视频处理要很久才能得到结果。可用索引（indexing）来解决这个额外难题，使用下面的代码可将图像所有的G(绿色)值设置为0
```
import cv2
import numpy as np
img = cv2.imread('MyPic.png')
img[:, :, 1] = 0
```


```python
import cv2
import numpy as np
# from matplotlib import pyplot as plt
img = cv2.imread('../fanleungTest/MyPic.png')
img[:, :, 1] = 0
cv2_imshow(img)

```

##### 感兴趣区域 （Region Of Interest, ROI）


```python
import cv2
import numpy as np
img = cv2.imread('../fanleungTest/MyPic.png')
my_roi = img[0:100, 0:100]
img[190:290, 190:290] = my_roi
cv2_imshow(img)
```


```python
import cv2
import numpy as np 
img = cv2.imread('../fanleungTest/MyPic.png')
print(img.shape)
print(img.size)
print(img.dtype)
```

    (290, 290, 3)
    252300
    uint8
    

##### 这三个属性分别为
- shape: 包括宽度、高度和通道数， 如果图像是单色或者灰度的，则不包含通道值
- size: 图像像素大小
- dtype: 图像的数据类型，一般为无符号整型，比如uint8

#### 2.1.4 视频文件的读/写


```python
# 将一幅图像传递给 videoWriter 的 write() 函数，该函数会将这个图像加载到VideoWrite()所指向的文件中
# 读取 avi 文件的帧，并采用 YUV 颜色编码将其写入另一个帧中:
# 把一个视频转化为另一个视频，即 MyInputVid 转化为 MyInputVid1,但是用不同的编码格式YUV
import cv2
videoCapture = cv2.VideoCapture('../fanleungTest/MyInputVid.avi')
# 读取这个视频的帧速
fps = videoCapture.get(cv2.CAP_PROP_FPS)
size = (int(videoCapture.get(cv2.CAP_PROP_FRAME_WIDTH)), int(videoCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))
videoWriter = cv2.VideoWriter('../fanleungTest/MyInputVid_converse.avi',
                             cv2.VideoWriter_fourcc('I', '4', '2', '0'),
                             fps, size)
success, frame = videoCapture.read()
while success:
    videoWriter.write(frame)
    success, frame = videoCapture.read()
    
    
```

注意： 必须要为VideoWriter类构建函数指定视频文件名，这个文件名对应的文件若存在，就会被覆盖。也必须指定视频编码解码器。编码解码器的可用性根据系统不同而不同，下面是一些常用选项：

- cv2.VideoWriter_fourcc（'I'，'4'，'2'，'0'）：该选项是一个未压缩的YUV颜色编码，是4:2:0色度子采样。这种编码有很好的兼容性，但会产生较大文件，文件扩展名为.avi
- cv2.VideoWriter_fourcc（'P'，'I'，'M'，'1'）：该选项是MPEG-1编码类型，文件扩展名为.avi
- cv2.VideoWriter_fourcc（'X'，'V'，'I'，'D'）：该选项是MPEG-4编码类型，如果希望得到的视频大小为平均值，推荐使用此选项，文件扩展名为.avi
- cv2.VideoWriter_fourcc（'T'，'H'，'E'，'O'）：该选项是Ogg Vorbis，文件扩展名应为.ogv
- cv2.VideoWriter_fourcc（'F'，'L'，'V'，'1'）：该选项是一个Flash视频，文件扩展名应为.flv

帧速率和帧大小也必须要指定，因为需要从另一个视频文件复制视频帧，这些属性可以通过VideoCapture类的get()函数得到。

#### 2.1.5 捕获摄像头的帧
VideoCapture 类可以获取摄像头的帧流，但对摄像头而言，通常不是用视频的文件名来构建 VideoCapture 类，而是需要传递摄像头的设备索引（device index）**(一个是视频文件，一个是摄像头)**

#### 捕获摄像头 10 秒的视频信息，并写入 MyOutputVid.avi


```python
import cv2
cameraCapture = cv2.VideoCapture(0)
fps = 30 # an assumption
size = (int(cameraCapture.get(cv2.CAP_PROP_FRAME_WIDTH)),
        int(cameraCapture.get(cv2.CAP_PROP_FRAME_HEIGHT)))
videoWriter = cv2.VideoWriter('../fanleungTest/MyOutputVid.avi', cv2.VideoWriter_fourcc('I', '4', '2', '0'),
                             fps, size)
success, frame = cameraCapture.read()
numFrameRemaining = 10 * fps - 1
while success and numFrameRemaining > 0:
    videoWriter.write(frame)
    success, frame = cameraCapture.read()
    numFrameRemaining -= 1
cameraCapture.release()

```

然而， VideoCapture.get() 方法不能返回摄像头帧速率的准确值，它总是返回 0, 于是只能假设一个帧速，或者用一个定时器来测量，这种办法会更好一些

#### 一组摄像头或一个多头摄像头
read() 方法不再适合了，可用grab()和retrive()方法替代它
```
success0 = cameraCapture0.grab()
success1 = cameraCapture1.grab()
if success0 and success1:
    frame0 = cameraCapture0.retrive()
    frame1 = cameraCapture1.retrive()
```

#### 2.1.6 在窗口显示图像


```python
import cv2
import numpy as np
img = cv2.imread('../fanleungTest/test.jpg')
cv2.imshow('my image', img)
cv2.waitKey()
cv2.destroyAllWindows()
```

调用destroyAllWindows()函数可以释放由OpenCV创建的所有窗口

#### 2.1.7 在窗口显示摄像头帧


```python
# 通过 setMouseCallback() 函数来获取鼠标输入，实时显示摄像头帧
import cv2
clicked = False
def onMouse(event, x, y, flags, param):
    global clicked
    if event == cv2.EVENT_LBUTTONUP:
        clicked = True

cameraCapture = cv2.VideoCapture(0)
cv2.namedWindow('MyWindow')
cv2.setMouseCallback('MyWindow', onMouse)

print('showing camera feed. click window or press any key to stop')

success, frame = cameraCapture.read()
while success and cv2.waitKey(1) == -1 and not clicked:
    cv2.imshow('Mywindow', frame)
    success, frame = cameraCapture.read()

cv2.destroyWindow('MyWindow')
cameraCapture.release()
```

    showing camera feed. click window or press any key to stop
    

### 2.2 Cameo 项目（人脸跟踪和图像处理）

### 2.3 Cameo -- 面向对象的设计
2.3.1 使用 managers.CaptureManager 提取视频流


```python
# managers.py
import cv2
import numpy
import time


class CaptureManager(object):
    
    def __init__(self, capture, previewWindowManager = None,
                 shouldMirrorPreview = False):
        
        self.previewWindowManager = previewWindowManager
        self.shouldMirrorPreview = shouldMirrorPreview
        
        self._capture = capture
        self._channel = 0
        self._enteredFrame = False
        self._frame = None
        self._imageFilename = None
        self._videoFilename = None
        self._videoEncoding = None
        self._videoWriter = None
        
        self._startTime = None
        self._framesElapsed = 0
        self._fpsEstimate = None
    
    @property
    def channel(self):
        return self._channel
    
    @channel.setter
    def channel(self, value):
        if self._channel != value:
            self._channel = value
            self._frame = None
    
    @property
    def frame(self):
        if self._enteredFrame and self._frame is None:
            # As of OpenCV 3.0, VideoCapture.retrieve() no longer supports
            # the channel argument.
            # _, self._frame = self._capture.retrieve(channel = self.channel)
            _, self._frame = self._capture.retrieve()
        return self._frame
    
    @property
    def isWritingImage(self):
        return self._imageFilename is not None
    
    @property
    def isWritingVideo(self):
        return self._videoFilename is not None
    
    def enterFrame(self):
        """Capture the next frame, if any."""
        
        # But first, check that any previous frame was exited.
        assert not self._enteredFrame, \
            'previous enterFrame() had no matching exitFrame()'
        
        if self._capture is not None:
            self._enteredFrame = self._capture.grab()
    
    def exitFrame(self):
        """Draw to the window. Write to files. Release the frame."""
        
        # Check whether any grabbed frame is retrievable.
        # The getter may retrieve and cache the frame.
        if self.frame is None:
            self._enteredFrame = False
            return
        
        # Update the FPS estimate and related variables.
        if self._framesElapsed == 0:
            self._startTime = time.time()
        else:
            timeElapsed = time.time() - self._startTime
            self._fpsEstimate =  self._framesElapsed / timeElapsed
        self._framesElapsed += 1
        
        # Draw to the window, if any.
        if self.previewWindowManager is not None:
            if self.shouldMirrorPreview:
                mirroredFrame = numpy.fliplr(self._frame).copy()
                self.previewWindowManager.show(mirroredFrame)
            else:
                self.previewWindowManager.show(self._frame)
        
        # Write to the image file, if any.
        if self.isWritingImage:
            cv2.imwrite(self._imageFilename, self._frame)
            self._imageFilename = None
        
        # Write to the video file, if any.
        self._writeVideoFrame()
        
        # Release the frame.
        self._frame = None
        self._enteredFrame = False
    
    def writeImage(self, filename):
        """Write the next exited frame to an image file."""
        self._imageFilename = filename
    
    def startWritingVideo(
            self, filename,
            encoding = cv2.VideoWriter_fourcc('M','J','P','G')):
        """Start writing exited frames to a video file."""
        self._videoFilename = filename
        self._videoEncoding = encoding
    
    def stopWritingVideo(self):
        """Stop writing exited frames to a video file."""
        self._videoFilename = None
        self._videoEncoding = None
        self._videoWriter = None
    
    def _writeVideoFrame(self):
        
        if not self.isWritingVideo:
            return
        
        if self._videoWriter is None:
            fps = self._capture.get(cv2.CAP_PROP_FPS)
            if fps <= 0.0:
                # The capture's FPS is unknown so use an estimate.
                if self._framesElapsed < 20:
                    # Wait until more frames elapse so that the
                    # estimate is more stable.
                    return
                else:
                    fps = self._fpsEstimate
            size = (int(self._capture.get(
                        cv2.CAP_PROP_FRAME_WIDTH)),
                    int(self._capture.get(
                        cv2.CAP_PROP_FRAME_HEIGHT)))
            self._videoWriter = cv2.VideoWriter(
                self._videoFilename, self._videoEncoding,
                fps, size)
        
        self._videoWriter.write(self._frame)


class WindowManager(object):
    
    def __init__(self, windowName, keypressCallback = None):
        self.keypressCallback = keypressCallback
        
        self._windowName = windowName
        self._isWindowCreated = False
    
    @property
    def isWindowCreated(self):
        return self._isWindowCreated
    
    def createWindow(self):
        cv2.namedWindow(self._windowName)
        self._isWindowCreated = True
    
    def show(self, frame):
        cv2.imshow(self._windowName, frame)
    
    def destroyWindow(self):
        cv2.destroyWindow(self._windowName)
        self._isWindowCreated = False
    
    def processEvents(self):
        keycode = cv2.waitKey(1)
        if self.keypressCallback is not None and keycode != -1:
            # Discard any non-ASCII info encoded by GTK.
            keycode &= 0xFF
            self.keypressCallback(keycode)

```


```python
# cameo.py

# 先运行上面的 managers.py
# 现在已经有一个能显示摄像头帧，监听键盘输入以及截图或录屏的应用了
import cv2

class Cameo(object):
    # 初始化 CaptureManager 类时， shouldMirrorPreview 为True, 导致摄像头被镜像，但是截图和录屏不会镜像
    def __init__(self):
        self._windowManager = WindowManager('Cameo',
                                            self.onKeypress)
        self._captureManager = CaptureManager(
            cv2.VideoCapture(0), self._windowManager, True)
    
    def run(self):
        """Run the main loop."""
        self._windowManager.createWindow()
        while self._windowManager.isWindowCreated:
            self._captureManager.enterFrame()
            frame = self._captureManager.frame
            
            if frame is not None:
                # TODO: Filter the frame (Chapter 3).
                pass
            
            self._captureManager.exitFrame()
            self._windowManager.processEvents()
    
    def onKeypress(self, keycode):
        """Handle a keypress.
        
        space  -> Take a screenshot.
        tab    -> Start/stop recording a screencast.
        escape -> Quit.
        
        """
        if keycode == 32: # space
            self._captureManager.writeImage('../fanleungTest/screenshot.png')
        elif keycode == 9: # tab
            if not self._captureManager.isWritingVideo:
                self._captureManager.startWritingVideo(
                    '../fanleungTest/screencast.avi')
            else:
                self._captureManager.stopWritingVideo()
        elif keycode == 27: # escape
            self._windowManager.destroyWindow()

if __name__=="__main__":
    Cameo().run()
```






